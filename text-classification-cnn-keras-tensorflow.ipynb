{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying product titles using convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text classification help us to better understand and organize data. Tried building a simple CNN classifier using Keras with tensorflow as backend to classify product available on ecommerce sites. Data for this expiriment are product titles of three distinct catgories from a popular ecommerce site. Reference: [Tutorial](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting data\n",
    "\n",
    "For this experiment I've collected product titles belonging to the following categories. \n",
    "\n",
    "* Women's clothing\n",
    "* Cameras\n",
    "* Home appliences\n",
    "\n",
    "Since these catgegories are distinct, meaning they dont have any overlap of contextual information, Our model should have less classification errors.\n",
    "\n",
    "Pre-trained vectors trained on part of Google News dataset [download 1.5GB](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing\n",
    "\n",
    "We need the following libraries\n",
    "* Gensim\n",
    "* Keras\n",
    "* NLTK\n",
    "* Pandas\n",
    "* Numpy\n",
    "\n",
    "[Conda](https://conda.io/docs/) to manage virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "MAX_NB_WORDS = 200000\n",
    "MAX_SEQUENCE_LENGTH = 30\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "EMBEDDING_FILE = \"../lib/GoogleNews-vectors-negative300.bin\"\n",
    "category_index = {\"clothing\":0, \"camera\":1, \"home-appliances\":2}\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "It is important to make sure that the data doesn't have any `null`/`Nan` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure there are no null values in the datasets\n",
      "Has null values:  False\n",
      "Has null values:  False\n",
      "Has null values:  False\n"
     ]
    }
   ],
   "source": [
    "clothing = pd.read_csv(\"clothing.tsv\", sep='\\t')\n",
    "cameras = pd.read_csv(\"cameras.tsv\", sep='\\t')\n",
    "home_appliances = pd.read_csv(\"home.tsv\", sep='\\t')\n",
    "\n",
    "datasets = [clothing, cameras, home_appliances]\n",
    "\n",
    "print(\"Make sure there are no null values in the datasets\")\n",
    "for data in datasets:\n",
    "    print(\"Has null values: \", data.isnull().values.any())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Stopwords or words that occur frequently and is distracting are removed first, Then we use classes provided by Keras to help prepare text so it can be used by neural network models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text= text.strip().lower().split()\n",
    "    text = filter(lambda word: word not in STOPWORDS, text)\n",
    "    return \" \".join(text)\n",
    "    \n",
    "for dataset in datasets:\n",
    "    dataset['title'] = dataset['title'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare the vector (array of integers) representation of text :\n",
    "* Combine titles from all three cateories to obtain a list of text.\n",
    "* Drop duplicates\n",
    "* Initialize tokenizer with `num_words = MAX_NB_WORDS` (200K). i.e. The tokenizer will perform a word count, sorted by number of occurences in descending order and pick top 200K words. \n",
    "* Use tokenizer's `texts_to_sequences` method to convert text to array of integers.\n",
    "* The arrays obtained from previous step might not be of uniform length, use `pad_sequences` method to obtain arrays with length equal to `MAX_SEQUENCE_LENGTH` (30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = clothing['title'] + cameras['title'] + home_appliances['title']\n",
    "all_texts = all_texts.drop_duplicates(keep=False)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(all_texts)\n",
    "\n",
    "clothing_sequences = tokenizer.texts_to_sequences(clothing['title'])\n",
    "electronics_sequences = tokenizer.texts_to_sequences(cameras['title'])\n",
    "home_appliances_sequences = tokenizer.texts_to_sequences(home_appliances['title'])\n",
    "\n",
    "clothing_data = pad_sequences(clothing_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "electronics_data = pad_sequences(electronics_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "home_appliances_data = pad_sequences(home_appliances_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `word_index` has a unique ID assigned to each word in the data. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word\t\tid\n",
      "--------------------\n",
      "sports\t\t16\n",
      "action\t\t13\n",
      "spy\t\t7\n",
      "pen\t\t55\n",
      "camera\t\t2\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "test_string = \"sports action spy pen camera\"\n",
    "print(\"word\\t\\tid\")\n",
    "print(\"-\" * 20)\n",
    "for word in test_string.split():\n",
    "    print(\"%s\\t\\t%s\" % (word, word_index[word]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenizer will replace words with unique integer id to get a vector representation of the title. \n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to Vector [[16, 13, 2], [7, 55, 2]]\n",
      "Padded Vector [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0 16 13  2]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  7 55  2]]\n"
     ]
    }
   ],
   "source": [
    "test_sequence = tokenizer.texts_to_sequences([\"sports action camera\", \"spy pen camera\"])\n",
    "padded_sequence = pad_sequences(test_sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print(\"Text to Vector\", test_sequence)\n",
    "print(\"Padded Vector\", padded_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product titles belonging to all three categories are kept separate so far for the sake of understanding. To prepare the input layer, All three cateogries are combined together and shuffled as shown below. \n",
    "\n",
    "The category (y-axis or label) is converted to convnet's understandable format by using the `keras.util` method `to_categorical`. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clothing: \t\t [ 1.  0.  0.]\n",
      "camera: \t\t [ 0.  1.  0.]\n",
      "home appliances: \t [ 0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"clothing: \\t\\t\", to_categorical(category_index[\"clothing\"], 3))\n",
    "print(\"camera: \\t\\t\", to_categorical(category_index[\"camera\"], 3))\n",
    "print(\"home appliances: \\t\", to_categorical(category_index[\"home-appliances\"], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clothing shape:  (392721, 30)\n",
      "electronics shape:  (1347, 30)\n",
      "home appliances shape:  (11425, 30)\n",
      "----------\n",
      "combined data shape:  (405493, 30)\n",
      "combined category/label shape:  (405493, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"clothing shape: \", clothing_data.shape)\n",
    "print(\"electronics shape: \", electronics_data.shape)\n",
    "print(\"home appliances shape: \", home_appliances_data.shape)\n",
    "\n",
    "data = np.vstack((clothing_data, electronics_data, home_appliances_data))\n",
    "category = pd.concat([clothing['category'], cameras['category'], home_appliances['category']]).values\n",
    "category = to_categorical(category)\n",
    "print(\"-\"*10)\n",
    "print(\"combined data shape: \", data.shape)\n",
    "print(\"combined category/label shape: \", category.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffling and spliting the data since categories are stacked one after the other. `nb_validation_samples` is the index which separetes training and testing/validating sets. This step can be simplified by [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) from scikit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT = 0.4\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "category = category[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = category[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = category[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec embeddings\n",
    "\n",
    "Word2Vec brings in semantic similarity info which can be leveraged by the convnets. This experiment uses pre-trained vectors from [Google news](https://code.google.com/archive/p/word2vec/).One other option is [GloVe](https://nlp.stanford.edu/projects/glove/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000000 word vectors of word2vec\n"
     ]
    }
   ],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "print('Found %s word vectors of word2vec' % len(word2vec.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following examples should help understand the intent behind using a pre trained word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odd word out: carrot\n",
      "----------\n",
      "Cosine similarity between TV and HBO: 0.613064891522\n",
      "----------\n",
      "Most similar words to Computers: computer, laptops, PCs, laptop_computers, desktop_computers, Computers, laptop, notebook_computers, Dell_OptiPlex_desktop, automated_seismographs\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#odd man out\n",
    "print(\"Odd word out:\", word2vec.doesnt_match(\"banana apple grapes carrot\".split()))\n",
    "print(\"-\"*10)\n",
    "print(\"Cosine similarity between TV and HBO:\", word2vec.similarity(\"tv\", \"hbo\"))\n",
    "print(\"-\"*10)\n",
    "print(\"Most similar words to Computers:\", \", \".join(map(lambda x: x[0], word2vec.most_similar(\"computers\"))))\n",
    "print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras embedding layer can be obtained by Gensim Word2Vec's `word2vec.get_keras_embedding(train_embeddings=False)` method or constructed like shown below. \n",
    "The null word embeddings indicate the number of words not found in our pre-trained vectors (In this case Google News). This could possibly be unque words for brands in this context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null word embeddings: 1473\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index))+1\n",
    "\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embedding_matrix[i] = word2vec.word_vec(word)\n",
    "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
    "\n",
    "embedding_layer = Embedding(embedding_matrix.shape[0], # or len(word_index) + 1\n",
    "                            embedding_matrix.shape[1], # or EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2724"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I recommend [this](https://www.youtube.com/watch?v=FmpDIaiMIeA) (30 Min) video about how Convnets work to understand the layers. \n",
    "Model explanation:\n",
    "1. Embedding layer as input\n",
    "2. A Dropout layer to avoid overfitting\n",
    "3. 1 dimentional convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 300)           817200    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 30, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 14, 300)           270300    \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 6, 150)            135150    \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 2, 75)             33825     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 453       \n",
      "=================================================================\n",
      "Total params: 1,279,578\n",
      "Trainable params: 462,378\n",
      "Non-trainable params: 817,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, Flatten\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(300, 3, padding='valid',activation='relu',strides=2))\n",
    "model.add(Conv1D(150, 3, padding='valid',activation='relu',strides=2))\n",
    "model.add(Conv1D(75, 3, padding='valid',activation='relu',strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(150,activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['acc'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 243296 samples, validate on 162197 samples\n",
      "Epoch 1/5\n",
      "243296/243296 [==============================] - 23s 93us/step - loss: 0.1219 - acc: 0.9734 - val_loss: 0.1086 - val_acc: 0.9771\n",
      "Epoch 2/5\n",
      "243296/243296 [==============================] - 23s 96us/step - loss: 0.1111 - acc: 0.9764 - val_loss: 0.1081 - val_acc: 0.9774\n",
      "Epoch 3/5\n",
      "243296/243296 [==============================] - 22s 89us/step - loss: 0.1108 - acc: 0.9769 - val_loss: 0.1080 - val_acc: 0.9775\n",
      "Epoch 4/5\n",
      "243296/243296 [==============================] - 23s 94us/step - loss: 0.1107 - acc: 0.9769 - val_loss: 0.1096 - val_acc: 0.9775\n",
      "Epoch 5/5\n",
      "243296/243296 [==============================] - 23s 95us/step - loss: 0.1112 - acc: 0.9769 - val_loss: 0.1104 - val_acc: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa87f94f7f0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv2d_6: expected ndim=4, found ndim=3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-6fe3b78fee54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dsenv/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    487\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m~/miniconda3/envs/dsenv/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dsenv/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    456\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv2d_6: expected ndim=4, found ndim=3"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D\n",
    "cnn = Sequential()\n",
    "cnn.add(embedding_layer)\n",
    "cnn.add(Conv2D(300, 3, strides=1, padding=\"same\", activation=\"relu\", input_shape=(1, 300, 1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
